{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc123b3b-fec2-4ef8-b644-1b43554912bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ../../dataset/unsupervised_dataset.duckdb (Table: training_data)\n",
      "Saving enhanced data to: ../../dataset/supervised_dataset.duckdb (Table: training_table_new_approach)\n"
     ]
    }
   ],
   "source": [
    "# Setup and Configuration\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import pickle\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# --- Input Configuration ---\n",
    "INPUT_DB_PATH = '../../dataset/unsupervised_dataset.duckdb'\n",
    "INPUT_TABLE_NAME = 'training_data'\n",
    "\n",
    "# --- Output Configuration ---\n",
    "OUTPUT_DB_PATH = '../../dataset/supervised_dataset.duckdb'\n",
    "OUTPUT_TABLE_NAME = 'training_table_new_approach'\n",
    "MODEL_SAVE_PATH = '../../models/unsupervised/iforest_model.pkl'\n",
    "\n",
    "print(f\"Loading data from: {INPUT_DB_PATH} (Table: {INPUT_TABLE_NAME})\")\n",
    "print(f\"Saving enhanced data to: {OUTPUT_DB_PATH} (Table: {OUTPUT_TABLE_NAME})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bca9e71-12c7-46c6-9cfb-0f64ff986122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading preprocessed data from 'training_data'...\n",
      "Successfully loaded 1000 users with 36 columns.\n",
      "Input database connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Load Preprocessed Data\n",
    "try:\n",
    "    con_input = duckdb.connect(database=INPUT_DB_PATH, read_only=True)\n",
    "    print(f\"\\nLoading preprocessed data from '{INPUT_TABLE_NAME}'...\")\n",
    "    df = con_input.query(f\"SELECT * FROM {INPUT_TABLE_NAME}\").to_df()\n",
    "    \n",
    "    if df.empty:\n",
    "        raise ValueError(f\"Table '{INPUT_TABLE_NAME}' is empty. Did 02_preprocessing run?\")\n",
    "    \n",
    "    print(f\"Successfully loaded {len(df)} users with {len(df.columns)} columns.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"--- CRITICAL ERROR: Could not load data ---\")\n",
    "    print(f\"Error: {e}\")\n",
    "    raise\n",
    "finally:\n",
    "    if 'con_input' in locals():\n",
    "        con_input.close()\n",
    "        print(\"Input database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e977ac5a-746f-4a74-ad57-6e927f7b262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data prepared. Training model on 35 features.\n",
      "First 5 features: ['total_logon_events', 'logon_unique_pcs', 'after_hours_logons', 'weekend_logons', 'logon_ratio']\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data for Modeling\n",
    "user_ids = df['user_id']\n",
    "\n",
    "X_train = df.drop(columns=['user_id'])\n",
    "\n",
    "features_used = X_train.columns.tolist()\n",
    "print(f\"\\nData prepared. Training model on {len(features_used)} features.\")\n",
    "print(f\"First 5 features: {features_used[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5d8f6de-ce73-44c9-9109-29ce611246de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Isolation Forest ---\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Train Isolation Forest Model\n",
    "print(\"\\n--- Training Isolation Forest ---\")\n",
    "\n",
    "# Instantiate the model\n",
    "model = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination='auto',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train)\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4237e6d3-8467-4865-a097-7c0cd7b0002f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating anomaly scores for all users...\n",
      "Scores generated.\n"
     ]
    }
   ],
   "source": [
    "# Generate Anomaly Scores\n",
    "\n",
    "print(\"Generating anomaly scores for all users...\")\n",
    "\n",
    "# .decision_function() gets the raw scores (negative = anomaly)\n",
    "raw_scores = model.decision_function(X_train)\n",
    "\n",
    "# Invert scores: higher = more anomalous\n",
    "anomaly_scores = -1 * raw_scores\n",
    "\n",
    "print(\"Scores generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a97dd03b-89c3-4b4c-9070-1153346b4b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation (Top 10 Anomalous Users) ---\n",
      "     user_id  anomaly_score\n",
      "60   ATE0869       0.156784\n",
      "64   DLM0051       0.142656\n",
      "914  RZC0746       0.141692\n",
      "454  TVS0006       0.128523\n",
      "921  KBP0008       0.127713\n",
      "915  WPR0368       0.127697\n",
      "162  HCS0003       0.124693\n",
      "65   LBF0214       0.115645\n",
      "66   NAF0326       0.115515\n",
      "836  HTH0007       0.115124\n",
      "\n",
      "--- Anomaly Score Statistics ---\n",
      "count    1000.000000\n",
      "mean       -0.064192\n",
      "std         0.051015\n",
      "min        -0.135961\n",
      "25%        -0.097849\n",
      "50%        -0.078691\n",
      "75%        -0.051263\n",
      "max         0.156784\n",
      "Name: anomaly_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 6. Inspect Results\n",
    "print(\"\\n--- Model Evaluation (Top 10 Anomalous Users) ---\")\n",
    "\n",
    "# Create a results DataFrame\n",
    "df_results = pd.DataFrame({\n",
    "    'user_id': user_ids,\n",
    "    'anomaly_score': anomaly_scores\n",
    "})\n",
    "\n",
    "# Sort by the score to see the \"most anomalous\" users\n",
    "df_results_sorted = df_results.sort_values(by='anomaly_score', ascending=False)\n",
    "\n",
    "# Print the top 10\n",
    "print(df_results_sorted.head(10))\n",
    "\n",
    "# Print basic stats for the scores\n",
    "print(\"\\n--- Anomaly Score Statistics ---\")\n",
    "print(df_results_sorted['anomaly_score'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65a623da-43a1-4296-bbcb-560c6f748cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving trained model to ../../models/unsupervised/iforest_model.pkl...\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# ## 7. Save Model Artifact\n",
    "\n",
    "print(f\"\\nSaving trained model to {MODEL_SAVE_PATH}...\")\n",
    "with open(MODEL_SAVE_PATH, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c40c1349-54e4-4593-8f3e-d0a8a0fca9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving enhanced data to new database: '../../dataset/supervised_dataset.duckdb'\n",
      "Enhanced data has 37 columns.\n",
      "Successfully created table 'training_table_new_approach' in '../../dataset/supervised_dataset.duckdb'.\n",
      "\n",
      "Verifying new table (first 5 rows):\n",
      "   user_id  total_logon_events  logon_unique_pcs  after_hours_logons  \\\n",
      "0  RAW0915                1203                28               414.0   \n",
      "1  JTM0223                1378               361               879.0   \n",
      "2  CCA0046                1608               447              1178.0   \n",
      "3  CIM0271                 997                 3               354.0   \n",
      "4  DFH0188                1133                 3               404.0   \n",
      "\n",
      "   weekend_logons  logon_ratio  logon_after_hours_ratio  logon_weekend_ratio  \\\n",
      "0           147.0     0.633416                 0.344140             0.122195   \n",
      "1             0.0     0.542816                 0.637881             0.000000   \n",
      "2             0.0     0.500000                 0.732587             0.000000   \n",
      "3             0.0     0.635908                 0.355065             0.000000   \n",
      "4             0.0     0.619594                 0.356575             0.000000   \n",
      "\n",
      "   total_http_events  http_unique_pcs  ...  extraversion  agreeableness  \\\n",
      "0              40300                1  ...            21             43   \n",
      "1              16026                1  ...            20             21   \n",
      "2              22744                1  ...            25             15   \n",
      "3              32870                1  ...            10             20   \n",
      "4              10034                1  ...            18             38   \n",
      "\n",
      "   neuroticism  unique_roles  unique_business_units  unique_functional_units  \\\n",
      "0           24             1                      1                        1   \n",
      "1           30             1                      1                        1   \n",
      "2           28             1                      1                        1   \n",
      "3           38             1                      1                        1   \n",
      "4           24             1                      1                        1   \n",
      "\n",
      "   unique_departments  unique_teams  unique_supervisors  anomaly_score  \n",
      "0                   1             1                   1       0.036566  \n",
      "1                   1             1                   1      -0.024567  \n",
      "2                   1             1                   1       0.019631  \n",
      "3                   1             1                   1      -0.076358  \n",
      "4                   1             1                   1      -0.083849  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "\n",
      "New table info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 37 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   user_id                  1000 non-null   object \n",
      " 1   total_logon_events       1000 non-null   int64  \n",
      " 2   logon_unique_pcs         1000 non-null   int64  \n",
      " 3   after_hours_logons       1000 non-null   float64\n",
      " 4   weekend_logons           1000 non-null   float64\n",
      " 5   logon_ratio              1000 non-null   float32\n",
      " 6   logon_after_hours_ratio  1000 non-null   float32\n",
      " 7   logon_weekend_ratio      1000 non-null   float32\n",
      " 8   total_http_events        1000 non-null   int64  \n",
      " 9   http_unique_pcs          1000 non-null   int64  \n",
      " 10  unique_urls_visited      1000 non-null   int64  \n",
      " 11  after_hours_http         1000 non-null   float64\n",
      " 12  weekend_http             1000 non-null   float64\n",
      " 13  http_after_hours_ratio   1000 non-null   float32\n",
      " 14  http_weekend_ratio       1000 non-null   float32\n",
      " 15  total_emails             1000 non-null   int64  \n",
      " 16  email_unique_pcs         1000 non-null   int64  \n",
      " 17  unique_recipients        1000 non-null   int64  \n",
      " 18  unique_cc                1000 non-null   int64  \n",
      " 19  unique_bcc               1000 non-null   int64  \n",
      " 20  unique_senders           1000 non-null   int64  \n",
      " 21  total_email_size         1000 non-null   float64\n",
      " 22  avg_email_size           1000 non-null   float64\n",
      " 23  total_attachments        1000 non-null   float64\n",
      " 24  avg_attachments          1000 non-null   float64\n",
      " 25  openness                 1000 non-null   int64  \n",
      " 26  conscientiousness        1000 non-null   int64  \n",
      " 27  extraversion             1000 non-null   int64  \n",
      " 28  agreeableness            1000 non-null   int64  \n",
      " 29  neuroticism              1000 non-null   int64  \n",
      " 30  unique_roles             1000 non-null   int64  \n",
      " 31  unique_business_units    1000 non-null   int64  \n",
      " 32  unique_functional_units  1000 non-null   int64  \n",
      " 33  unique_departments       1000 non-null   int64  \n",
      " 34  unique_teams             1000 non-null   int64  \n",
      " 35  unique_supervisors       1000 non-null   int64  \n",
      " 36  anomaly_score            1000 non-null   float64\n",
      "dtypes: float32(5), float64(9), int64(22), object(1)\n",
      "memory usage: 269.7+ KB\n",
      "\n",
      "Output database connection to '../../dataset/supervised_dataset.duckdb' closed. Script finished.\n"
     ]
    }
   ],
   "source": [
    "# Save Enhanced Data to output db\n",
    "print(f\"\\nSaving enhanced data to new database: '{OUTPUT_DB_PATH}'\")\n",
    "\n",
    "# Add the new anomaly_score column to our original preprocessed data\n",
    "df_enhanced = df.copy() # Start with the 'training_data' (36 cols)\n",
    "df_enhanced['anomaly_score'] = anomaly_scores # Add the new score (37 cols total)\n",
    "\n",
    "print(f\"Enhanced data has {len(df_enhanced.columns)} columns.\")\n",
    "\n",
    "# --- Save to NEW DuckDB ---\n",
    "try:\n",
    "    con_output = duckdb.connect(database=OUTPUT_DB_PATH, read_only=False)\n",
    "    \n",
    "    # Register the enhanced DataFrame\n",
    "    con_output.register('df_enhanced_view', df_enhanced)\n",
    "    \n",
    "    # Drop the target table if it already exists\n",
    "    con_output.execute(f\"DROP TABLE IF EXISTS {OUTPUT_TABLE_NAME}\")\n",
    "    \n",
    "    # Create the new table\n",
    "    con_output.execute(f\"CREATE TABLE {OUTPUT_TABLE_NAME} AS SELECT * FROM df_enhanced_view\")\n",
    "    \n",
    "    print(f\"Successfully created table '{OUTPUT_TABLE_NAME}' in '{OUTPUT_DB_PATH}'.\")\n",
    "    \n",
    "    # Verify by checking the new table\n",
    "    print(\"\\nVerifying new table (first 5 rows):\")\n",
    "    final_table = con_output.query(f\"SELECT * FROM {OUTPUT_TABLE_NAME} LIMIT 5\").to_df()\n",
    "    print(final_table)\n",
    "    print(\"\\nNew table info:\")\n",
    "    con_output.table(OUTPUT_TABLE_NAME).to_df().info()\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"--- ERROR while saving enhanced data: {e} ---\")\n",
    "finally:\n",
    "    if 'con_output' in locals():\n",
    "        con_output.close()\n",
    "    print(f\"\\nOutput database connection to '{OUTPUT_DB_PATH}' closed. Script finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Insider Threat Detection Venv)",
   "language": "python",
   "name": "insider_threat_detection_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
