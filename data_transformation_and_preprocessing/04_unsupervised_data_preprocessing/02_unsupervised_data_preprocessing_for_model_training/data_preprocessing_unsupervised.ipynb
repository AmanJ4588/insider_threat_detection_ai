{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6140ebb7-5aed-4e75-97bb-3d63174e046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Configuration\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "# --- Configuration ---\n",
    "DUCKDB_PATH = '../../dataset/unsupervised_dataset.duckdb' \n",
    "SOURCE_TABLE_NAME = 'user_features'\n",
    "TARGET_TABLE_NAME = 'training_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "362c251a-3e57-476c-8a55-2db12ec5c2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 35 total columns to drop.\n"
     ]
    }
   ],
   "source": [
    "# Columns to Drop (Based on EDA)\n",
    "\n",
    "# 1. Identifier columns (keeping 'user_id' as our key)\n",
    "id_cols_to_drop = [\n",
    "    'psychometric_employee_name',\n",
    "    'ldap_employee_name'\n",
    "]\n",
    "\n",
    "# 2. Columns with >73% missing data\n",
    "missing_data_cols_to_drop = [\n",
    "    'total_device_events',\n",
    "    'connect_count',\n",
    "    'disconnect_count',\n",
    "    'device_unique_pcs',\n",
    "    'after_hours_connects',\n",
    "    'weekend_connects',\n",
    "    'connect_ratio',\n",
    "    'device_after_hours_ratio',\n",
    "    'device_weekend_ratio',\n",
    "    'total_file_events',\n",
    "    'file_unique_pcs',\n",
    "    'unique_files',\n",
    "    'unique_file_types',\n",
    "    'exe_files_accessed',\n",
    "    'zip_files_accessed',\n",
    "    'pdf_files_accessed',\n",
    "    'docx_files_accessed',\n",
    "    'xlsx_files_accessed',\n",
    "    'after_hours_file_events',\n",
    "    'weekend_file_events',\n",
    "    'file_after_hours_ratio',\n",
    "    'file_weekend_ratio',\n",
    "    'exe_ratio',\n",
    "    'zip_ratio',\n",
    "    'pdf_ratio',\n",
    "    'docx_ratio',\n",
    "    'xlsx_ratio'\n",
    "]\n",
    "\n",
    "# 3. Columns with zero variance (all values are 0)\n",
    "zero_variance_cols_to_drop = [\n",
    "    'role_changed',\n",
    "    'department_changed',\n",
    "    'team_changed'\n",
    "]\n",
    "\n",
    "# 4. Redundant features (highly correlated)\n",
    "redundant_cols_to_drop = [\n",
    "    'logon_count',\n",
    "    'logoff_count',\n",
    "    'emails_with_attachments'\n",
    "]\n",
    "\n",
    "# Combine all lists\n",
    "all_cols_to_drop = (\n",
    "    id_cols_to_drop +\n",
    "    missing_data_cols_to_drop +\n",
    "    zero_variance_cols_to_drop +\n",
    "    redundant_cols_to_drop\n",
    ")\n",
    "\n",
    "print(f\"Defined {len(all_cols_to_drop)} total columns to drop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799998dc-f719-4e0e-b1e4-c790b0d0c878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data from 'user_features'...\n",
      "Loaded 1000 users with 71 features.\n",
      "Found 35 columns to drop that exist in the table.\n",
      "\n",
      "--- Preprocessing Summary ---\n",
      "Original feature count: 71\n",
      "Dropped feature count:  35\n",
      "Final feature count:    36 (including 'user_id')\n",
      "\n",
      "Saving preprocessed data to 'training_data'...\n",
      "Successfully created table 'training_data'.\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Load, Process, and Save Data\n",
    "\n",
    "try:\n",
    "    # --- Load Source Data ---\n",
    "    con = duckdb.connect(database=DUCKDB_PATH, read_only=False) # Read-write access\n",
    "    print(f\"Loading raw data from '{SOURCE_TABLE_NAME}'...\")\n",
    "    df = con.query(f\"SELECT * FROM {SOURCE_TABLE_NAME}\").to_df()\n",
    "    \n",
    "    original_cols = df.columns.tolist()\n",
    "    original_count = len(original_cols)\n",
    "    print(f\"Loaded {len(df)} users with {original_count} features.\")\n",
    "\n",
    "    # --- Identify columns that actually exist in the DF to avoid errors ---\n",
    "    cols_to_drop_existing = [col for col in all_cols_to_drop if col in original_cols]\n",
    "    print(f\"Found {len(cols_to_drop_existing)} columns to drop that exist in the table.\")\n",
    "\n",
    "    # --- Preprocessing: Drop the columns ---\n",
    "    df_preprocessed = df.drop(columns=cols_to_drop_existing)\n",
    "    final_count = len(df_preprocessed.columns)\n",
    "    \n",
    "    print(f\"\\n--- Preprocessing Summary ---\")\n",
    "    print(f\"Original feature count: {original_count}\")\n",
    "    print(f\"Dropped feature count:  {len(cols_to_drop_existing)}\")\n",
    "    print(f\"Final feature count:    {final_count} (including 'user_id')\")\n",
    "\n",
    "    # --- Save to New Table ---\n",
    "    print(f\"\\nSaving preprocessed data to '{TARGET_TABLE_NAME}'...\")\n",
    "    \n",
    "    # Register the DataFrame to make it available to DuckDB\n",
    "    con.register('df_preprocessed_view', df_preprocessed)\n",
    "    \n",
    "    # Drop the target table if it already exists \n",
    "    con.execute(f\"DROP TABLE IF EXISTS {TARGET_TABLE_NAME}\")\n",
    "    \n",
    "    # Create the new table from the registered DataFrame\n",
    "    con.execute(f\"CREATE TABLE {TARGET_TABLE_NAME} AS SELECT * FROM df_preprocessed_view\")\n",
    "    \n",
    "    print(f\"Successfully created table '{TARGET_TABLE_NAME}'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- AN ERROR OCCURRED ---\")\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    # Always close the connection\n",
    "    if 'con' in locals():\n",
    "        con.close()\n",
    "    print(\"Database connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce59cb02-2850-4ffd-ac87-89deb2a0f9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verification Step ---\n",
      "Successfully loaded data from new table 'training_data'.\n",
      "First 5 rows:\n",
      "   user_id  total_logon_events  logon_unique_pcs  after_hours_logons  \\\n",
      "0  RAW0915                1203                28               414.0   \n",
      "1  JTM0223                1378               361               879.0   \n",
      "2  CCA0046                1608               447              1178.0   \n",
      "3  CIM0271                 997                 3               354.0   \n",
      "4  DFH0188                1133                 3               404.0   \n",
      "\n",
      "   weekend_logons  logon_ratio  logon_after_hours_ratio  logon_weekend_ratio  \\\n",
      "0           147.0     0.633416                 0.344140             0.122195   \n",
      "1             0.0     0.542816                 0.637881             0.000000   \n",
      "2             0.0     0.500000                 0.732587             0.000000   \n",
      "3             0.0     0.635908                 0.355065             0.000000   \n",
      "4             0.0     0.619594                 0.356575             0.000000   \n",
      "\n",
      "   total_http_events  http_unique_pcs  ...  conscientiousness  extraversion  \\\n",
      "0              40300                1  ...                 50            21   \n",
      "1              16026                1  ...                 48            20   \n",
      "2              22744                1  ...                 43            25   \n",
      "3              32870                1  ...                 27            10   \n",
      "4              10034                1  ...                 40            18   \n",
      "\n",
      "   agreeableness  neuroticism  unique_roles  unique_business_units  \\\n",
      "0             43           24             1                      1   \n",
      "1             21           30             1                      1   \n",
      "2             15           28             1                      1   \n",
      "3             20           38             1                      1   \n",
      "4             38           24             1                      1   \n",
      "\n",
      "   unique_functional_units  unique_departments  unique_teams  \\\n",
      "0                        1                   1             1   \n",
      "1                        1                   1             1   \n",
      "2                        1                   1             1   \n",
      "3                        1                   1             1   \n",
      "4                        1                   1             1   \n",
      "\n",
      "   unique_supervisors  \n",
      "0                   1  \n",
      "1                   1  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   1  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "\n",
      "Verifying final table structure:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 36 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   user_id                  1000 non-null   object \n",
      " 1   total_logon_events       1000 non-null   int64  \n",
      " 2   logon_unique_pcs         1000 non-null   int64  \n",
      " 3   after_hours_logons       1000 non-null   float64\n",
      " 4   weekend_logons           1000 non-null   float64\n",
      " 5   logon_ratio              1000 non-null   float32\n",
      " 6   logon_after_hours_ratio  1000 non-null   float32\n",
      " 7   logon_weekend_ratio      1000 non-null   float32\n",
      " 8   total_http_events        1000 non-null   int64  \n",
      " 9   http_unique_pcs          1000 non-null   int64  \n",
      " 10  unique_urls_visited      1000 non-null   int64  \n",
      " 11  after_hours_http         1000 non-null   float64\n",
      " 12  weekend_http             1000 non-null   float64\n",
      " 13  http_after_hours_ratio   1000 non-null   float32\n",
      " 14  http_weekend_ratio       1000 non-null   float32\n",
      " 15  total_emails             1000 non-null   int64  \n",
      " 16  email_unique_pcs         1000 non-null   int64  \n",
      " 17  unique_recipients        1000 non-null   int64  \n",
      " 18  unique_cc                1000 non-null   int64  \n",
      " 19  unique_bcc               1000 non-null   int64  \n",
      " 20  unique_senders           1000 non-null   int64  \n",
      " 21  total_email_size         1000 non-null   float64\n",
      " 22  avg_email_size           1000 non-null   float64\n",
      " 23  total_attachments        1000 non-null   float64\n",
      " 24  avg_attachments          1000 non-null   float64\n",
      " 25  openness                 1000 non-null   int64  \n",
      " 26  conscientiousness        1000 non-null   int64  \n",
      " 27  extraversion             1000 non-null   int64  \n",
      " 28  agreeableness            1000 non-null   int64  \n",
      " 29  neuroticism              1000 non-null   int64  \n",
      " 30  unique_roles             1000 non-null   int64  \n",
      " 31  unique_business_units    1000 non-null   int64  \n",
      " 32  unique_functional_units  1000 non-null   int64  \n",
      " 33  unique_departments       1000 non-null   int64  \n",
      " 34  unique_teams             1000 non-null   int64  \n",
      " 35  unique_supervisors       1000 non-null   int64  \n",
      "dtypes: float32(5), float64(8), int64(22), object(1)\n",
      "memory usage: 261.8+ KB\n",
      "\n",
      "Final table has 36 columns, as expected.\n",
      "Verification connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Verification \n",
    "print(\"\\n--- Verification Step ---\")\n",
    "try:\n",
    "    con = duckdb.connect(database=DUCKDB_PATH, read_only=True)\n",
    "    verify_df = con.query(f\"SELECT * FROM {TARGET_TABLE_NAME} LIMIT 5\").to_df()\n",
    "    \n",
    "    print(f\"Successfully loaded data from new table '{TARGET_TABLE_NAME}'.\")\n",
    "    print(\"First 5 rows:\")\n",
    "    print(verify_df)\n",
    "\n",
    "    print(\"\\nVerifying final table structure:\")\n",
    "    # Get full info\n",
    "    verify_all_df = con.query(f\"SELECT * FROM {TARGET_TABLE_NAME}\").to_df()\n",
    "    verify_all_df.info()\n",
    "    \n",
    "    # Expected final count: 71 - 33 = 38\n",
    "    print(f\"\\nFinal table has {len(verify_all_df.columns)} columns, as expected.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during verification: {e}\")\n",
    "finally:\n",
    "    if 'con' in locals():\n",
    "        con.close()\n",
    "    print(\"Verification connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Insider Threat Detection Venv)",
   "language": "python",
   "name": "insider_threat_detection_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
